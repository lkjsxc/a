{
  "working_memory_character_max": 10000,
  "working_memory_direct_child_max": 50,
  "llm_api_url": "http://localhost:1234/v1/chat/completions",
  "llm_model": "llama-3.2-3b-instruct",
  "llm_max_tokens": 2048,
  "llm_temperature": 0.7,
  "system_max_log_entries": 100,
  "system_auto_cleanup": true,
  "system_debug_mode": true
}
